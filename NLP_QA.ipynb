{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_QA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8mzgV5a6CNS"
      },
      "source": [
        "## **Webscrapp questions and answers from 3 websites**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03v0jo8UFx7v"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for the code to function well, you have to have these packages versions\n",
        "import bs4\n",
        "assert requests.__version__ == '2.23.0'\n",
        "assert bs4.__version__ == '4.6.3'\n",
        "assert pd.__version__ == '1.1.4'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqrzK4wn2RAT"
      },
      "source": [
        "questions = []\n",
        "answers = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36s0ussw6SUO"
      },
      "source": [
        "Website 1 : https://onlinecoursetutorials.com/interview-questions/natural-language-processing-interview-questions-and-answers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ShPEEv2eX9kL",
        "outputId": "8bb04ed7-40c4-46e3-e4ee-e95ff608436a"
      },
      "source": [
        "page = requests.get('https://onlinecoursetutorials.com/interview-questions/natural-language-processing-interview-questions-and-answers/')\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "questions_list = soup.find(class_='the_content')\n",
        "questions_list_items = questions_list.find_all(['strong'])\n",
        "\n",
        "for i,_ in enumerate(questions_list_items):\n",
        "  question = questions_list_items[i]\n",
        "  question = str(question).replace('<h3>','')\n",
        "  question = str(question).replace('</h3>','')\n",
        "  question = str(question).replace('<strong>','')\n",
        "  question = str(question).replace('</strong>','')\n",
        "  questions_list_items[i] = question\n",
        "\n",
        "# Remove questions with no answer\n",
        "questions_list_items.pop(21)\n",
        "questions_list_items.pop(8)\n",
        "questions_list_items.pop(9)\n",
        "questions_list_items.pop(11)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How can you find synonyms and antonyms for a word ?\\xa0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKbnYGtx2XZV"
      },
      "source": [
        "for q in questions_list_items:\n",
        "  questions.append(q)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qx18DZ4OmSRK",
        "outputId": "bcc69b9f-6cf3-4e73-99bd-e4c9fe58e98d"
      },
      "source": [
        "page = requests.get('https://onlinecoursetutorials.com/interview-questions/natural-language-processing-interview-questions-and-answers/')\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "\n",
        "answers_list = soup.find(class_='the_content')\n",
        "\n",
        "answers_list_items = answers_list.find_all(['td'])\n",
        "\n",
        "for i,_ in enumerate(answers_list_items):\n",
        "  answer = answers_list_items[i]\n",
        "  answer = str(answer).replace('<td>','')\n",
        "  answer = str(answer).replace('</td>','')\n",
        "  answers_list_items[i] = answer\n",
        "\n",
        "answers_list_items.pop(0)\n",
        "\n",
        "for i in range(len(answers_list_items)-1,-1,-1):\n",
        "  if str(answers_list_items[i]).startswith(\"<strong>\") or len(str(answers_list_items[i]))<1:\n",
        "    answers_list_items.pop(i)\n",
        "\n",
        "answers_list_items.pop(27)\n",
        "answers_list_items.pop(26)\n",
        "answers_list_items.pop(25)\n",
        "answers_list_items.pop(24)\n",
        "\n",
        "answers_list_items.pop(12)\n",
        "answers_list_items.pop(11)\n",
        "answers_list_items.pop(10)\n",
        "answers_list_items.pop(9)\n",
        "answers_list_items.pop(8)\n",
        "answers_list_items.pop(11)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<a href=\"https://onlinecoursetutorials.com/nlp/synonyms-and-antonyms-from-nltk-wordnet-in-python/\">Refer here</a>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9eijBdW2-dX"
      },
      "source": [
        "for a in answers_list_items:\n",
        "  answers.append(a)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBjidoxJ6mHy"
      },
      "source": [
        "Website 2 : https://learning.shine.com/talenteconomy/career-help/nlp-interview-questions/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6OjQ-OxhZ9zn",
        "outputId": "5e5fc5a7-b8b6-45ff-d3dc-5724bfa613c8"
      },
      "source": [
        "page = requests.get('https://learning.shine.com/talenteconomy/career-help/nlp-interview-questions/')\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "questions_list = soup.find(class_='article-content')\n",
        "\n",
        "questions_list_items = questions_list.find_all(['strong'])\n",
        "\n",
        "for i,_ in enumerate(questions_list_items):\n",
        "  question = questions_list_items[i]\n",
        "  question = str(question).replace('<strong>','')\n",
        "  question = str(question).replace('</strong>','')\n",
        "  questions_list_items[i] = question\n",
        "\n",
        "# Remove questions with no answer\n",
        "questions_list_items.pop(20)\n",
        "questions_list_items.pop(17)\n",
        "questions_list_items.pop(13)\n",
        "questions_list_items.pop(10)\n",
        "questions_list_items.pop(8)\n",
        "questions_list_items.pop(4)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tell me the steps involved in solving an NLP Problem?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K879y-Ww2opV"
      },
      "source": [
        "for q in questions_list_items:\n",
        "  questions.append(q)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hJXLJGg0axkP",
        "outputId": "e30f42ea-91a8-4e9c-b7cb-1949efff6504"
      },
      "source": [
        "page = requests.get('https://learning.shine.com/talenteconomy/career-help/nlp-interview-questions/')\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "answers_list = soup.find(class_='article-content')\n",
        "\n",
        "answers_list_items = answers_list.find_all(['p'])\n",
        "\n",
        "for i,_ in enumerate(answers_list_items):\n",
        "  answer = answers_list_items[i]\n",
        "  answer = str(answer).replace('<p>','')\n",
        "  answer = str(answer).replace('</p>','')\n",
        "  answers_list_items[i] = answer\n",
        "\n",
        "answers_list_items.pop(35)\n",
        "answers_list_items.pop(34)\n",
        "\n",
        "for i in range(32,19,-1):\n",
        "  answers_list_items.pop(i)\n",
        "\n",
        "answers_list_items.pop(18)\n",
        "answers_list_items.pop(14)\n",
        "answers_list_items.pop(11)\n",
        "answers_list_items.pop(9)\n",
        "answers_list_items.pop(5)\n",
        "answers_list_items.pop(0)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'If you’re finding a job that is related to NLP, then you have to prepare for the questions to be put by the interviewer. Every interview is diverse as per the diverse job profiles. Here, we have equipped the significant NLP interview questions and answers, which will help you get accomplishment in your interview.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STUHGUP93FmI"
      },
      "source": [
        "for a in answers_list_items:\n",
        "  answers.append(a)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tRDV1Px6zuK"
      },
      "source": [
        "Website 3 : https://www.codingtag.com/nlp-interview-questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jNgAVHoI3_Xy",
        "outputId": "79f6dfa7-e4ab-4d24-9a6c-67afbc1a88ac"
      },
      "source": [
        "page = requests.get('https://www.codingtag.com/nlp-interview-questions')\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "questions_list = soup.find(class_='entry-summary')\n",
        "\n",
        "questions_list_items = questions_list.find_all(['h3'])\n",
        "\n",
        "for i,_ in enumerate(questions_list_items):\n",
        "  question = questions_list_items[i]\n",
        "  question = str(question).replace('<h3>','')\n",
        "  question = str(question).replace('</h3>','')\n",
        "  question = question[3:]\n",
        "  questions_list_items[i] = question\n",
        "\n",
        "questions_list_items.pop(14)\n",
        "questions_list_items.pop(10)\n",
        "questions_list_items.pop(8)\n",
        "questions_list_items.pop(2)\n",
        "questions_list_items.pop(1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What are the defining components of NLP?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFLHBNku4Int"
      },
      "source": [
        "for q in questions_list_items:\n",
        "  questions.append(q)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ctYOmlEb4FFa",
        "outputId": "e016872e-0b89-4218-a75d-c365cae8d450"
      },
      "source": [
        "answers_list = soup.find(class_='entry-summary')\n",
        "answers_list_items = answers_list.find_all(['h3'])\n",
        "\n",
        "for i,_ in enumerate(answers_list_items):\n",
        "  answer = answers_list_items[i]\n",
        "  next_tag = answer.findNext('p')\n",
        "  next_tag = str(next_tag).replace('<p>','')\n",
        "  next_tag = str(next_tag).replace('</p>','')\n",
        "  answers_list_items[i] = next_tag\n",
        "\n",
        "\n",
        "answers_list_items.pop(14)\n",
        "answers_list_items.pop(10)\n",
        "answers_list_items.pop(8)\n",
        "answers_list_items.pop(2)\n",
        "answers_list_items.pop(1)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The major defining components of NLP are:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLUTe4Kx4GwI"
      },
      "source": [
        "for a in answers_list_items:\n",
        "  answers.append(a)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgSwWnaWXfLp"
      },
      "source": [
        "Visualize questions and answers in a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "550MJ9gb4VWt",
        "outputId": "33f189aa-617f-4139-e02e-f5c70fea11cc"
      },
      "source": [
        "dict = {'Questions': questions, 'Answers': answers}  \n",
        "    \n",
        "df = pd.DataFrame(dict) \n",
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is NLP(natural language processing) ?</td>\n",
              "      <td>Natural language processing is a subfield of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is applications of NLP ?</td>\n",
              "      <td>Text classification, Text summarization, Name ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is tokenization ?</td>\n",
              "      <td>Splitting the sentence into words</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is stemming ?</td>\n",
              "      <td>Stemming is the process of reducing a word to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is lemmatizing ?</td>\n",
              "      <td>Lemmatizing is also same like stemming but the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is Normalization ?</td>\n",
              "      <td>Converting different range of values to same s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is POS (parts of speech) tagging ?</td>\n",
              "      <td>Tagging a word with noun, pronoun, adverd, adj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is NER (name entity recognition)?</td>\n",
              "      <td>NER refers to name entiyy recognization like p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What are stop words ?</td>\n",
              "      <td>a, the , an etc like repeated words in text, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is Noise Removal ?</td>\n",
              "      <td>Remove unwanted data from corpus. Like if you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is Wordnet ?</td>\n",
              "      <td>WordNet is a lexical database for the English ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is NLG (Natural language Generation) ?</td>\n",
              "      <td>It’s about generating new text from understand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is NLU (Natural language understanding) ?</td>\n",
              "      <td>It’s about understanding of natural language. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What is Corpus ?</td>\n",
              "      <td>It’s a collection of text documents.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What is N- Gram, Unigram, Bigram  and Trigram?</td>\n",
              "      <td>it’s about word analysis, unigram means single...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What is Language modeling ?</td>\n",
              "      <td>A statistical language model is a probability ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What is Latent semantic analysis ?</td>\n",
              "      <td>Latent semantic analysis is a technique in nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What is word embedding ?</td>\n",
              "      <td>Word embedding is the collective name for a se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What is word2vec ?</td>\n",
              "      <td>Word2vec is a group of related models that are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What is Glove ?</td>\n",
              "      <td>GloVe, coined from Global Vectors, is a model ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>What is Fasttext ?</td>\n",
              "      <td>fastText is a library for learning of word emb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>What is Genism ?</td>\n",
              "      <td>Gensim is a production-ready open-source libra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>What is text mining ?</td>\n",
              "      <td>Text mining, also referred to as text data min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>What is Information Extraction ?</td>\n",
              "      <td>Information extraction is the task of automati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>What is object standardization ? When it will ...</td>\n",
              "      <td>Text data often contains words or phrases whic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>What is text generation ? When we will do it ?</td>\n",
              "      <td>Generate new text from understanding old data.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>What is text summarization ? When we will do it ?</td>\n",
              "      <td>Automatic summarization is the process of shor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>What do you mean by NLP?</td>\n",
              "      <td>Natural Language Processing is a programmed wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Tell me the significance of TF-IDF?</td>\n",
              "      <td>TFIDF refers to term frequency opposite docume...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>What do you mean by tokenization in NLP?</td>\n",
              "      <td>Natural Language Processing aims to plan compu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Define Pragmatic Analysis?</td>\n",
              "      <td>The pragmatic analysis is a significant task i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>What is the F1 score in NLP?</td>\n",
              "      <td>F1 score evaluates the subjective standard of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>What do you mean by Regular Grammar?</td>\n",
              "      <td>A regular grammar comprises a system in the sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Define dependency parsing in NLP?</td>\n",
              "      <td>Dependency parsing is single of the serious ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Define Lemmatization in NLP?</td>\n",
              "      <td>Lemmatization usually means to do the things s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>What are bigrams, unigrams and n-grams in NLP?</td>\n",
              "      <td>When we parse a ruling one word at a time, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Define Regular Expressions?</td>\n",
              "      <td>A regular expression is used to contest and ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Name some popular models other than a bag of w...</td>\n",
              "      <td>Indexing, Latent semantic word2vec.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Where NER can be used?</td>\n",
              "      <td>Scanning documents for categorization, custome...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Define parsing in the context of NLP?</td>\n",
              "      <td>Parsing a document means to function out the g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>How to check word similarity using the spacy ...</td>\n",
              "      <td>To find out the comparison among words, we use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Define Named entity recognition?</td>\n",
              "      <td>Named-entity recognition is the process of ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>What is NLP?</td>\n",
              "      <td>NLP, the acronym for Natural Language Processi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>What is tokenization in NLP?</td>\n",
              "      <td>Tokenization is the process through which a se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>What is Latent Semantic Analysis?</td>\n",
              "      <td>Latent Semantic Analysis is the process throug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Define the concept of POS (Parts of Speech) ta...</td>\n",
              "      <td>Parts of Speech (POS) Tagging is the process t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>How is Named Entity Recognition (NER) used in ...</td>\n",
              "      <td>In NLP, Named Entity Recognition is a process ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>What is TF-IDF and what significance does it p...</td>\n",
              "      <td>TF-IDF stands for Term Frequency- Inverse Docu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>What are stop words in NLP? And how can we fi...</td>\n",
              "      <td>Stop words in NLP refers to the words such as ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>What is Word Embedding in NLP?</td>\n",
              "      <td>Word Embedding is the process of Natural Langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>What are NLG and NLU?</td>\n",
              "      <td>NLG refers to the Natural Language Generation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>What is dependency parsing in NLP?</td>\n",
              "      <td>Dependency parsing in NLP is a process through...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Questions                                            Answers\n",
              "0          What is NLP(natural language processing) ?  Natural language processing is a subfield of c...\n",
              "1                       What is applications of NLP ?  Text classification, Text summarization, Name ...\n",
              "2                              What is tokenization ?                  Splitting the sentence into words\n",
              "3                                 What is stemming ?   Stemming is the process of reducing a word to ...\n",
              "4                              What is lemmatizing ?   Lemmatizing is also same like stemming but the...\n",
              "5                            What is Normalization ?   Converting different range of values to same s...\n",
              "6            What is POS (parts of speech) tagging ?   Tagging a word with noun, pronoun, adverd, adj...\n",
              "7              What is NER (name entity recognition)?  NER refers to name entiyy recognization like p...\n",
              "8                              What are stop words ?   a, the , an etc like repeated words in text, t...\n",
              "9                            What is Noise Removal ?   Remove unwanted data from corpus. Like if you ...\n",
              "10                                 What is Wordnet ?   WordNet is a lexical database for the English ...\n",
              "11        What is NLG (Natural language Generation) ?  It’s about generating new text from understand...\n",
              "12     What is NLU (Natural language understanding) ?  It’s about understanding of natural language. ...\n",
              "13                                  What is Corpus ?                It’s a collection of text documents.\n",
              "14    What is N- Gram, Unigram, Bigram  and Trigram?   it’s about word analysis, unigram means single...\n",
              "15                       What is Language modeling ?   A statistical language model is a probability ...\n",
              "16                 What is Latent semantic analysis ?  Latent semantic analysis is a technique in nat...\n",
              "17                           What is word embedding ?  Word embedding is the collective name for a se...\n",
              "18                                What is word2vec ?   Word2vec is a group of related models that are...\n",
              "19                                   What is Glove ?   GloVe, coined from Global Vectors, is a model ...\n",
              "20                                What is Fasttext ?   fastText is a library for learning of word emb...\n",
              "21                                   What is Genism ?  Gensim is a production-ready open-source libra...\n",
              "22                             What is text mining ?   Text mining, also referred to as text data min...\n",
              "23                  What is Information Extraction ?   Information extraction is the task of automati...\n",
              "24  What is object standardization ? When it will ...  Text data often contains words or phrases whic...\n",
              "25     What is text generation ? When we will do it ?     Generate new text from understanding old data.\n",
              "26  What is text summarization ? When we will do it ?  Automatic summarization is the process of shor...\n",
              "27                           What do you mean by NLP?  Natural Language Processing is a programmed wa...\n",
              "28                Tell me the significance of TF-IDF?  TFIDF refers to term frequency opposite docume...\n",
              "29           What do you mean by tokenization in NLP?  Natural Language Processing aims to plan compu...\n",
              "30                         Define Pragmatic Analysis?  The pragmatic analysis is a significant task i...\n",
              "31                       What is the F1 score in NLP?  F1 score evaluates the subjective standard of ...\n",
              "32               What do you mean by Regular Grammar?  A regular grammar comprises a system in the sh...\n",
              "33                  Define dependency parsing in NLP?  Dependency parsing is single of the serious ta...\n",
              "34                       Define Lemmatization in NLP?  Lemmatization usually means to do the things s...\n",
              "35     What are bigrams, unigrams and n-grams in NLP?  When we parse a ruling one word at a time, the...\n",
              "36                        Define Regular Expressions?  A regular expression is used to contest and ta...\n",
              "37  Name some popular models other than a bag of w...                Indexing, Latent semantic word2vec.\n",
              "38                             Where NER can be used?  Scanning documents for categorization, custome...\n",
              "39              Define parsing in the context of NLP?  Parsing a document means to function out the g...\n",
              "40   How to check word similarity using the spacy ...  To find out the comparison among words, we use...\n",
              "41                   Define Named entity recognition?  Named-entity recognition is the process of ext...\n",
              "42                                       What is NLP?  NLP, the acronym for Natural Language Processi...\n",
              "43                       What is tokenization in NLP?  Tokenization is the process through which a se...\n",
              "44                  What is Latent Semantic Analysis?  Latent Semantic Analysis is the process throug...\n",
              "45  Define the concept of POS (Parts of Speech) ta...  Parts of Speech (POS) Tagging is the process t...\n",
              "46  How is Named Entity Recognition (NER) used in ...  In NLP, Named Entity Recognition is a process ...\n",
              "47  What is TF-IDF and what significance does it p...  TF-IDF stands for Term Frequency- Inverse Docu...\n",
              "48   What are stop words in NLP? And how can we fi...  Stop words in NLP refers to the words such as ...\n",
              "49                     What is Word Embedding in NLP?  Word Embedding is the process of Natural Langu...\n",
              "50                              What are NLG and NLU?  NLG refers to the Natural Language Generation ...\n",
              "51                 What is dependency parsing in NLP?  Dependency parsing in NLP is a process through..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0MepXrBOlA1"
      },
      "source": [
        "## **Use the BERT model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qanyKQ6-uwx",
        "outputId": "ee9fec52-5239-4801-c2c8-840d3d69f71f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTdjBFgq-6DE"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGm7GDTf_Hwt"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edqm7qjk_nfY"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yRjatAkIGCM"
      },
      "source": [
        "This function takes a question and a text containing the answer and finds the right answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "016sbzerBAKU"
      },
      "source": [
        "def answer_question(question, answer_text):\n",
        "\n",
        "    # tokenize\n",
        "    input_ids = tokenizer.encode(question, answer_text)\n",
        "\n",
        "    # find the input_ids for the first sep token\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    num_seg_a = sep_index + 1\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    # list of 0 and 1\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "\n",
        "    start_scores, end_scores = output[0], output[1]\n",
        "    \n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "        if tokens[i][0:2] == '##':\n",
        "            answer += tokens[i][2:]\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "\n",
        "    return answer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZmyPYa3Kae8"
      },
      "source": [
        "This function is used because the BERT model cannot find the answers if the number of tokens is greater than 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGHad3iUcuLi"
      },
      "source": [
        "def reponse(question, answers, n=0, precedent_answers=[], k=0):\n",
        "\n",
        "    def max_p(question, answers):\n",
        "        p = len(answers)\n",
        "        while len(tokenizer.encode(question, \" \".join(answers[:p]))) > 512:\n",
        "            p -= 1\n",
        "        if p <= 0:\n",
        "            return None\n",
        "        return p\n",
        "\n",
        "    def decoupe(question, answers, decoupes=[]):\n",
        "        if len(answers) == 0:\n",
        "            return [0] + decoupes\n",
        "        p = max_p(question, answers)\n",
        "        return decoupe(question, answers[p:], decoupes + [p])\n",
        "\n",
        "    decoupes = decoupe(question, answers)\n",
        "    for i in range(1, len(decoupes)):\n",
        "        decoupes[i] = decoupes[i-1] + decoupes[i]\n",
        "    answers_decoupes = [answers[decoupes[i]:decoupes[i+1]] for i in range(len(decoupes) - 1)]\n",
        "\n",
        "    bert_answers0 = [answer_question(question, \" \".join(answer)) for answer in answers_decoupes]\n",
        "\n",
        "    bert_answers = []\n",
        "\n",
        "    for answer in bert_answers0:\n",
        "      if \"[\" not in answer and not answer in bert_answers:\n",
        "        bert_answers.append(answer)\n",
        "\n",
        "\n",
        "    #print(max_p(question, answers))\n",
        "    #print(decoupes)\n",
        "    #print(len(answers), answers)\n",
        "    #print(answers_decoupes)\n",
        "    print(len(bert_answers), bert_answers)\n",
        "    #print(n)\n",
        "\n",
        "    if len(bert_answers) == 1:\n",
        "        return bert_answers[0]\n",
        "\n",
        "    if len(bert_answers)==0:\n",
        "      return\n",
        "    \n",
        "\n",
        "    new_answers = []\n",
        "    for answer in answers:\n",
        "        for bert_answer in bert_answers:\n",
        "\n",
        "            if bert_answer.lower() in answer.lower() and answer not in new_answers:\n",
        "                new_answers.append(answer)\n",
        "    np.random.shuffle(new_answers)\n",
        "\n",
        "    if len(new_answers) == len(answers):\n",
        "        k += 1\n",
        "    else:\n",
        "        k = 0\n",
        "\n",
        "    print(len(new_answers), new_answers)\n",
        "\n",
        "    return reponse(question, new_answers, n+1, answers, k)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QvtCfZtQthx"
      },
      "source": [
        "## **Ask a question**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCVLAjNnQ5S6",
        "outputId": "4ad113b4-9411-4a57-ae76-61e48810086a"
      },
      "source": [
        "question = \"What is the meaning of tokenization ?\"\n",
        "\n",
        "print(\"Question : \", question)\n",
        "print(\"Answer : \", reponse(question, answers))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1926 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Question :  What is the meaning of tokenization ?\n",
            "3 ['dividing the text into a variety of tokens', 'the process through which a sentence is split into smaller words known as tokens , containing the same character sequence', 'syntactic structure']\n",
            "2 ['Natural Language Processing aims to plan computers to route large amounts of natural language data. Tokenization in NLP means the technique of dividing the text into a variety of tokens. You can think of a coupon in the shape of the word. Just like a word forms into a sentence.', 'Dependency parsing in NLP is a process through which a sentence is assigned syntactic structure by analyzing the terms included.']\n",
            "1 ['the technique of dividing the text into a variety of tokens']\n",
            "Answer :  the technique of dividing the text into a variety of tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_DTN_T_SK51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6fb540-7b1b-4de9-92c6-034e7a7f8f40"
      },
      "source": [
        "question = \"Can you explain the notion of word embedding ?\"\n",
        "\n",
        "print(\"Question : \", question)\n",
        "print(\"Answer : \", reponse(question, answers))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question :  Can you explain the notion of word embedding ?\n",
            "5 ['a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers', 'word2vec is a group of related models that are used to produce word embeddings . these models are shallow , two - layer neural networks that are trained to reconstruct linguistic contexts of words', 'you', 'natural language processing which is based on language modeling and feature learning', 'dependency parsing in nlp is a process through which a sentence is assigned syntactic structure by analyzing the terms included']\n",
            "5 ['Remove unwanted data from corpus. Like if you are working sentiment analysis, we have to remove ?”! etc.', 'Word Embedding is the process of Natural Language Processing which is based on language modeling and feature learning.', 'Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers', 'Dependency parsing in NLP is a process through which a sentence is assigned syntactic structure by analyzing the terms included.', 'Natural Language Processing aims to plan computers to route large amounts of natural language data. Tokenization in NLP means the technique of dividing the text into a variety of tokens. You can think of a coupon in the shape of the word. Just like a word forms into a sentence.']\n",
            "1 ['words or phrases from the vocabulary are mapped to vectors of real numbers']\n",
            "Answer :  words or phrases from the vocabulary are mapped to vectors of real numbers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbQEIHZhUZ7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e589e1ad-7238-4caa-9c2b-b5bcecf81fdb"
      },
      "source": [
        "question = \"Is stemming like lemmatization ?\"\n",
        "\n",
        "print(\"Question : \", question)\n",
        "print(\"Answer : \", reponse(question, answers))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question :  Is stemming like lemmatization ?\n",
            "3 ['lemmatizing', 'le', 'dependency parsing']\n",
            "30 ['Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.', 'NLP, the acronym for Natural Language Processing, is a method which is used to analyze and process the natural languages in order to make it understandable by the machines.', 'Lemmatizing is also same like stemming but the difference is lemmantizing words known with dictionary.', 'it’s about word analysis, unigram means single word, bigram means double words and trigram means tripple word.', 'Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing', 'F1 score evaluates the subjective standard of recall and precision. It considers both false unconstructive and false constructive instances while evaluating the model. F1 score is more answerable than accurateness for an NLP model when there is a rough allocation of class.', 'In NLP, Named Entity Recognition is a process through which the named entities such as people, place, events, etc. are derived from a sentence and are further classified into predefined categories.', 'Lemmatization usually means to do the things suitably with the use of vocabulary and morphological investigation of words. In this method, the endings of the words are detached to revisit the base word, which is also known as Lemma.', 'Gensim is a production-ready open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning. Gensim is implemented in Python and Cython for top performance and scalability', 'A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability to the whole sequence. The language model provides context to distinguish between words and phrases that sound simila', 'Text data often contains words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models.', 'Dependency parsing is single of the serious tasks in NLP. It allows the examination of a ruling using parsing algorithms. Also, by using the parse tree independence parsing, we can ensure the grammar and examine the semantic arrangement of a sentence.', 'Dependency parsing in NLP is a process through which a sentence is assigned syntactic structure by analyzing the terms included.', 'GloVe, coined from Global Vectors, is a model for distributed word representation. The model is an unsupervised learning algorithm for obtaining vector representations for words. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity.', 'Converting different range of values to same scale from 0 to 1.', 'A regular grammar comprises a system in the shape of A -&gt; a, A -&gt; aB and many more. The rules help sense and examine strings by automatic computation.', 'The pragmatic analysis is a significant task in NLP for interpreting knowledge that is laying exterior a given document. The plan of implementing pragmatic analysis is to spotlight on exploring a diverse aspect of the document or text in a language. The pragmatic analysis permits software applications for the serious interpretation of the real-world data to know the definite meaning of sentences and words.', 'When we parse a ruling one word at a time, then it is called a unigram. The ruling parsed two words at a time are a bigram. When the ruling is parsed three words at a time, then it is a trigram. Likewise, n-gram refers to the parsing of n languages at a time.', 'Natural Language Processing is a programmed way to understand or consider the natural languages and remove necessary information from such data by applying machine learning Algorithms.', 'Parsing a document means to function out the grammatical constitution of sentences, for example, which groups of words go mutually (as “phrases”) and which words are the topic or object of a verb. Probabilistic parsers use the information of language gained from hand-parsed sentences to try to create the most likely examination of new sentences.', 'It’s a collection of text documents.', 'Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning', 'fastText is a library for learning of word embeddings and text classification created by Facebook’s AI Research lab. The model allows to create an unsupervised learning or supervised learning algorithm for obtaining vector representations for words', 'TF-IDF stands for Term Frequency- Inverse Document Frequency. In Natural Language Processing, TD-IDF is used as a numerical analysis which determines how important a term is in context to any document or the collections.', 'Tokenization is the process through which a sentence is split into smaller words known as tokens, containing the same character sequence.', 'WordNet is a lexical database for the English language. It groups English words into sets of synonyms called synsets, provides short definitions and usage examples, and records a number of relations among these synonym sets or their members.', 'Word Embedding is the process of Natural Language Processing which is based on language modeling and feature learning.', 'Named-entity recognition is the process of extracting information. It arranges and classifies named unit in the shapeless text in diverse categories like locations, time expressions, percentages, and monetary values. It allows the users to appreciate the subject of the text properly.', 'Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers', 'Scanning documents for categorization, customer support (chatbots, understanding feedback) and unit recognition in molecular biology (names of genes etc.)']\n",
            "2 ['lemmatizing', 'tokenization']\n",
            "2 ['Tokenization is the process through which a sentence is split into smaller words known as tokens, containing the same character sequence.', 'Lemmatizing is also same like stemming but the difference is lemmantizing words known with dictionary.']\n",
            "1 ['lemmatizing is also same like stemming']\n",
            "Answer :  lemmatizing is also same like stemming\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ZwNMXTVJw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36fd2727-a34d-4135-b0f9-1071777d7022"
      },
      "source": [
        "question = \"What is NLP ?\"\n",
        "\n",
        "print(\"Question : \", question)\n",
        "print(\"Answer : \", reponse(question, answers))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question :  What is NLP ?\n",
            "3 ['a', 'the technique of dividing the text into a variety of tokens', 'natural language processing']\n",
            "51 ['fastText is a library for learning of word embeddings and text classification created by Facebook’s AI Research lab. The model allows to create an unsupervised learning or supervised learning algorithm for obtaining vector representations for words', 'F1 score evaluates the subjective standard of recall and precision. It considers both false unconstructive and false constructive instances while evaluating the model. F1 score is more answerable than accurateness for an NLP model when there is a rough allocation of class.', 'Text data often contains words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models.', 'GloVe, coined from Global Vectors, is a model for distributed word representation. The model is an unsupervised learning algorithm for obtaining vector representations for words. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity.', 'When we parse a ruling one word at a time, then it is called a unigram. The ruling parsed two words at a time are a bigram. When the ruling is parsed three words at a time, then it is a trigram. Likewise, n-gram refers to the parsing of n languages at a time.', 'Gensim is a production-ready open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning. Gensim is implemented in Python and Cython for top performance and scalability', 'TFIDF refers to term frequency opposite document occurrence. In information retrieval, TFIDF is an arithmetical statistic that is planned to reproduce how significant a word is to a text in a compilation.', 'Tagging a word with noun, pronoun, adverd, adjective etc.', 'Stop words in NLP refers to the words such as a, an; which does not imposes any value to the context of the sentence and omission of which, will not cause any change to the original meaning of the sentence.', 'Dependency parsing in NLP is a process through which a sentence is assigned syntactic structure by analyzing the terms included.', 'Latent semantic analysis is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms', 'Named-entity recognition is the process of extracting information. It arranges and classifies named unit in the shapeless text in diverse categories like locations, time expressions, percentages, and monetary values. It allows the users to appreciate the subject of the text properly.', 'it’s about word analysis, unigram means single word, bigram means double words and trigram means tripple word.', 'Lemmatization usually means to do the things suitably with the use of vocabulary and morphological investigation of words. In this method, the endings of the words are detached to revisit the base word, which is also known as Lemma.', 'Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning', 'Word Embedding is the process of Natural Language Processing which is based on language modeling and feature learning.', 'Converting different range of values to same scale from 0 to 1.', 'It’s a collection of text documents.', 'Natural Language Processing is a programmed way to understand or consider the natural languages and remove necessary information from such data by applying machine learning Algorithms.', 'It’s about understanding of natural language. How humans are communicating in different scenarios.', 'Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words', 'Natural language processing is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human languages, in particular how to program computers to process and analyze large amounts of natural language data', 'A regular expression is used to contest and tag words. It consists of a sequence of characters for identical strings. Imagine, if X and Y are regular expressions, then the next is true for them:', 'Remove unwanted data from corpus. Like if you are working sentiment analysis, we have to remove ?”! etc.', 'Scanning documents for categorization, customer support (chatbots, understanding feedback) and unit recognition in molecular biology (names of genes etc.)', 'To find out the comparison among words, we use word likeness. We appraise the similarity with the assist of a number that lies between 0 and 1.', 'Generate new text from understanding old data.', 'NLG refers to the Natural Language Generation where a new language is developed by processing the data from an old language.', 'Parts of Speech (POS) Tagging is the process through which the software, tagger, is used to label the words in a sentence with the help of an algorithm which then, assigns a parts of speech to every term or token analyzed in the given sentence.', 'Tokenization is the process through which a sentence is split into smaller words known as tokens, containing the same character sequence.', 'A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability to the whole sequence. The language model provides context to distinguish between words and phrases that sound simila', 'Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers', 'Dependency parsing is single of the serious tasks in NLP. It allows the examination of a ruling using parsing algorithms. Also, by using the parse tree independence parsing, we can ensure the grammar and examine the semantic arrangement of a sentence.', 'Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes.', 'Text classification, Text summarization, Name entity recognization, part of speech tagging, language model building, Machine translation, Spell checking, speech recognization, character recognization.', 'Latent Semantic Analysis is the process through which the relationship between any sets of documents and the containing terms are determined through the generation of concept related to that terms or documents.', 'The pragmatic analysis is a significant task in NLP for interpreting knowledge that is laying exterior a given document. The plan of implementing pragmatic analysis is to spotlight on exploring a diverse aspect of the document or text in a language. The pragmatic analysis permits software applications for the serious interpretation of the real-world data to know the definite meaning of sentences and words.', 'a, the , an etc like repeated words in text, that doesn’t give any additional value to context. we can filter those words by using nltk library standard function.', 'A regular grammar comprises a system in the shape of A -&gt; a, A -&gt; aB and many more. The rules help sense and examine strings by automatic computation.', 'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.', 'It’s about generating new text from understanding old data.', 'Indexing, Latent semantic word2vec.', 'WordNet is a lexical database for the English language. It groups English words into sets of synonyms called synsets, provides short definitions and usage examples, and records a number of relations among these synonym sets or their members.', 'Parsing a document means to function out the grammatical constitution of sentences, for example, which groups of words go mutually (as “phrases”) and which words are the topic or object of a verb. Probabilistic parsers use the information of language gained from hand-parsed sentences to try to create the most likely examination of new sentences.', 'NLP, the acronym for Natural Language Processing, is a method which is used to analyze and process the natural languages in order to make it understandable by the machines.', 'Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing', 'NER refers to name entiyy recognization like places, organizations, companies etc.', 'Natural Language Processing aims to plan computers to route large amounts of natural language data. Tokenization in NLP means the technique of dividing the text into a variety of tokens. You can think of a coupon in the shape of the word. Just like a word forms into a sentence.', 'TF-IDF stands for Term Frequency- Inverse Document Frequency. In Natural Language Processing, TD-IDF is used as a numerical analysis which determines how important a term is in context to any document or the collections.', 'Lemmatizing is also same like stemming but the difference is lemmantizing words known with dictionary.', 'In NLP, Named Entity Recognition is a process through which the named entities such as people, place, events, etc. are derived from a sentence and are further classified into predefined categories.']\n",
            "3 ['dependency parsing', 'natural language generation', 'natural language processing']\n",
            "13 ['Natural Language Processing aims to plan computers to route large amounts of natural language data. Tokenization in NLP means the technique of dividing the text into a variety of tokens. You can think of a coupon in the shape of the word. Just like a word forms into a sentence.', 'Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers', 'TF-IDF stands for Term Frequency- Inverse Document Frequency. In Natural Language Processing, TD-IDF is used as a numerical analysis which determines how important a term is in context to any document or the collections.', 'Gensim is a production-ready open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning. Gensim is implemented in Python and Cython for top performance and scalability', 'Natural language processing is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human languages, in particular how to program computers to process and analyze large amounts of natural language data', 'Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing', 'NLG refers to the Natural Language Generation where a new language is developed by processing the data from an old language.', 'Word Embedding is the process of Natural Language Processing which is based on language modeling and feature learning.', 'Natural Language Processing is a programmed way to understand or consider the natural languages and remove necessary information from such data by applying machine learning Algorithms.', 'Dependency parsing is single of the serious tasks in NLP. It allows the examination of a ruling using parsing algorithms. Also, by using the parse tree independence parsing, we can ensure the grammar and examine the semantic arrangement of a sentence.', 'NLP, the acronym for Natural Language Processing, is a method which is used to analyze and process the natural languages in order to make it understandable by the machines.', 'Dependency parsing in NLP is a process through which a sentence is assigned syntactic structure by analyzing the terms included.', 'Latent semantic analysis is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms']\n",
            "1 ['the acronym for natural language processing']\n",
            "Answer :  the acronym for natural language processing\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}